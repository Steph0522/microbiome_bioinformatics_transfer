[["index.html", "Introducción práctica a la bioinformática de microbiotas en R y Rstudio Prefacio 0.1 Objetivos del curso 0.2 Público a quien va dirigido 0.3 Pre-requisitos", " Introducción práctica a la bioinformática de microbiotas en R y Rstudio Prefacio Este libro contiene los temas y códigos a ver en el taller “Introducción práctica a la bioinformática de microbiotas en R y Rstudio”. 0.1 Objetivos del curso Que los asistentes adquieran habilidades prácticas y un conocimiento avanzado sobre herramientas de bioinformática en el estudio de microbiotas usando R y Rstudio 0.2 Público a quien va dirigido Este curso está dirigido a estudiantes y profesionistas que están familiarizados con el uso de R y Rstudio y desean adquirir habilidades en el análisis de datos de secuenciación masiva y microbiotas usando R y Rstudio. En este curso aprenderás a usar un flujo de trabajo en el que se importarán, se procesarán y se analizarán datos de microbiomas de un estudio de transferencia materna de microbiota. 0.3 Pre-requisitos Conocimiento básico en R y Rstudio Equipo de cómputo (16GB de RAM y 1 GB de espacio) "],["descargando-las-secuencias-del-ncbi.html", "TEMA 1 : Descargando las secuencias del NCBI 1.1 Descargar secuencias con SRAtoolkit 1.2 Descargando Secuencias ejemplo", " TEMA 1 : Descargando las secuencias del NCBI Las secuencias que utilizaremos son del artículo: Montoya-Ciriaco, Nina, et al. “Maternal transmission of bacterial microbiota during embryonic development in a viviparous lizard.” Microbiology Spectrum 11.6 (2023): e01780-23. Para descargar las secuencias del NCBI hay varias opciones: Página de NCBI: Esto lo podemos hacerde forma manual con el número de Bioproject, por ejemplo: PRJNA963006. SRAtoolkit: Para instalar esta herramienta, consultar esta liga. Hay otras herramientas como bash linux, aspera connect, qiime2-fondue, etc. 1.1 Descargar secuencias con SRAtoolkit Archivo con los SRA ids, sra_ids.txt: SRR1234567 SRR1234568 SRR1234569 mkdir -p ./fastq_output while read srr; do echo &quot;Procesando $srr ...&quot; # 1. Descargar el .sra si no existe if [ ! -f ./sra_files/$srr.sra ]; then mkdir -p ./sra_files prefetch -O ./sra_files $srr fi # 2. Convertir a FASTQ gzip fasterq-dump ./sra_files/$srr.sra \\ --split-files \\ --origfmt \\ --gzip \\ -O ./fastq_output done &lt; sra_ids.txt 1.2 Descargando Secuencias ejemplo Lo primero que haremos será crear un directorio donde depositaremos los archivos de ejemplo. Luego, vamos a descargar las secuencias que vamos a utilizar para este ejemplo y descomprimirlas. Liga a las secuencias Sugerencia: Abrir un proyecto nuevo para este taller donde deposites las secuencias y vayas poniendo el script y código. "],["importar-secuencias-a-rstudio.html", "TEMA 2 : Importar secuencias a Rstudio", " TEMA 2 : Importar secuencias a Rstudio Ya habiendo descargado las secuencias podemos importarlas a Rstudio para ser procesadas. # Ajuste de rutas y directorio de trabajo # ruta que contiene los archivos fastq ruta_fastq &lt;- &quot;C:/Users/shere/Documents/microbiome_bioinformatics_transfer/Datos/seqs_transfer/&quot; # Crear carpeta para guardar resultados y ajusta directorio de trabajo ruta_resultados &lt;-&quot;C:/Users/shere/Documents/microbiome_bioinformatics_transfer/resultados&quot; setwd(ruta_resultados) fnFs &lt;- sort(list.files(ruta_fastq, pattern = &quot;_1.fastq.gz&quot;, full.names = TRUE)) fnRs &lt;- sort(list.files(ruta_fastq, pattern = &quot;_2.fastq.gz&quot;, full.names = TRUE)) head(fnFs) [1] &quot;C:/Users/shere/Documents/microbiome_bioinformatics_transfer/Datos/seqs_transfer/SRR24359981_1.fastq.gz&quot; [2] &quot;C:/Users/shere/Documents/microbiome_bioinformatics_transfer/Datos/seqs_transfer/SRR24359982_1.fastq.gz&quot; [3] &quot;C:/Users/shere/Documents/microbiome_bioinformatics_transfer/Datos/seqs_transfer/SRR24359983_1.fastq.gz&quot; [4] &quot;C:/Users/shere/Documents/microbiome_bioinformatics_transfer/Datos/seqs_transfer/SRR24359984_1.fastq.gz&quot; [5] &quot;C:/Users/shere/Documents/microbiome_bioinformatics_transfer/Datos/seqs_transfer/SRR24359985_1.fastq.gz&quot; [6] &quot;C:/Users/shere/Documents/microbiome_bioinformatics_transfer/Datos/seqs_transfer/SRR24359986_1.fastq.gz&quot; head(fnRs) [1] &quot;C:/Users/shere/Documents/microbiome_bioinformatics_transfer/Datos/seqs_transfer/SRR24359981_2.fastq.gz&quot; [2] &quot;C:/Users/shere/Documents/microbiome_bioinformatics_transfer/Datos/seqs_transfer/SRR24359982_2.fastq.gz&quot; [3] &quot;C:/Users/shere/Documents/microbiome_bioinformatics_transfer/Datos/seqs_transfer/SRR24359983_2.fastq.gz&quot; [4] &quot;C:/Users/shere/Documents/microbiome_bioinformatics_transfer/Datos/seqs_transfer/SRR24359984_2.fastq.gz&quot; [5] &quot;C:/Users/shere/Documents/microbiome_bioinformatics_transfer/Datos/seqs_transfer/SRR24359985_2.fastq.gz&quot; [6] &quot;C:/Users/shere/Documents/microbiome_bioinformatics_transfer/Datos/seqs_transfer/SRR24359986_2.fastq.gz&quot; "],["remoción-de-primers.html", "TEMA 3 : Remoción de primers", " TEMA 3 : Remoción de primers Instalar librerías a usar en todo el flujo de trabajo install.packages(&quot;tidyverse&quot;) if (!require(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;) BiocManager::install(&quot;phyloseq&quot;) BiocManager::install(&quot;Biostrings&quot;) BiocManager::install(&quot;dada2&quot;) BiocManager::install(&quot;ShortRead&quot;) Cargar librerías library(dada2) library(Biostrings) library(ShortRead) Primers y sus reversos complementarios # Primers usados en PCR FWD &lt;- &quot;CCTACGGGNGGCWGCAG&quot; REV &lt;- &quot;GACTACHVGGGTATCTAATCC&quot; allOrients &lt;- function(primer) { require(Biostrings) dna &lt;- DNAString(primer) orients &lt;- c(Forward = dna, Complement = complement(dna), Reverse = reverse(dna), RevComp = reverseComplement(dna)) return(sapply(orients, toString)) # Convertir de nuevo a vector de caracteres } # Determinar todas las orientaciones posibles de los primers FWD.orients &lt;- allOrients(FWD) REV.orients &lt;- allOrients(REV) FWD.orients Forward Complement Reverse RevComp &quot;CCTACGGGNGGCWGCAG&quot; &quot;GGATGCCCNCCGWCGTC&quot; &quot;GACGWCGGNGGGCATCC&quot; &quot;CTGCWGCCNCCCGTAGG&quot; Filtrado previo para detección de primers #esta parte toma aprox: 9 min # Crear un directorio nuevo con filtrado fnFs.filtN &lt;- file.path(ruta_resultados, &quot;filtN&quot;, basename(fnFs)) fnRs.filtN &lt;- file.path(ruta_resultados, &quot;filtN&quot;, basename(fnRs)) filterAndTrim(fnFs, fnFs.filtN, fnRs, fnRs.filtN, maxN = 0, multithread = TRUE) Detectar si hay primers presentes primerHits &lt;- function(primer, fn) { # Cuenta el numero de lecturas en donde se encontraron primers nhits &lt;- vcountPattern(primer, sread(readFastq(fn)), fixed = FALSE) return(sum(nhits &gt; 0)) } # Crear tabla para la deteccion de los primers primeres_detected &lt;- rbind(FWD.ForwardReads = sapply(FWD.orients, primerHits, fn = fnFs.filtN[[1]]), FWD.ReverseReads = sapply(FWD.orients, primerHits, fn = fnRs.filtN[[1]]), REV.ForwardReads = sapply(REV.orients, primerHits, fn = fnFs.filtN[[1]]), REV.ReverseReads = sapply(REV.orients, primerHits, fn = fnRs.filtN[[1]])) primeres_detected Forward Complement Reverse RevComp 1 FWD.ForwardReads 5201 0 0 0 2 FWD.ReverseReads 0 0 0 7 3 REV.ForwardReads 0 0 0 4 4 REV.ReverseReads 5184 0 0 0 Remoción de primers con cutadapt Cutadapt es una herramienta que nos permitirá remover los primers que se encuentren aún en las secuencias. Este programa se debe descargar según el sistema operativo y colocar la ruta. Para correr cutadpat en R debemos instalar cutadapt y para usarlo en windows debemos instalar: Python3 Visual studio con la opción de C++ y Python tools. Luego, abrimos la terminal de comandos de windows (cmd.exe) y corremos: py -m pip install cutadapt Si quedó bien instalada nos dará la versión instalada, con este código: py -m cutadapt --version #poner ruta aquí cutadapt &lt;- &quot;C:/Users/shere/AppData/Local/Programs/Python/Python314/Scripts/cutadapt.exe&quot; # en mi pc está aquí system2(cutadapt, args = &quot;--version&quot;) #correr cutadapt path.cut &lt;- file.path(ruta_fastq, &quot;cutadapt&quot;) if(!dir.exists(path.cut)) dir.create(path.cut) fnFs.cut &lt;- file.path(path.cut, basename(fnFs)) fnRs.cut &lt;- file.path(path.cut, basename(fnRs)) FWD.RC &lt;- dada2:::rc(FWD) REV.RC &lt;- dada2:::rc(REV) R1.flags &lt;- paste(&quot;-g&quot;, FWD, &quot;-a&quot;, REV.RC) R2.flags &lt;- paste(&quot;-G&quot;, REV, &quot;-A&quot;, FWD.RC) # Correr Cutadapt for (i in seq_along(fnFs)) { system2( cutadapt, args = c( R1.flags, R2.flags, &quot;-n&quot;,2, &quot;-o&quot;, fnFs.cut[i], &quot;-p&quot;,fnRs.cut[i], fnFs.filtN[i], fnRs.filtN[i], &quot;--minimum-length=1&quot; ) ) } Detectar si fueron removidos los primers primers_detected_despues = rbind( FWD.ForwardReads = sapply(FWD.orients, primerHits, fn = fnFs.cut[[1]]), FWD.ReverseReads = sapply(FWD.orients, primerHits, fn = fnRs.cut[[1]]), REV.ForwardReads = sapply(REV.orients, primerHits, fn = fnFs.cut[[1]]), REV.ReverseReads = sapply(REV.orients, primerHits, fn = fnRs.cut[[1]]) ) Forward Complement Reverse RevComp 1 FWD.ForwardReads 0 0 0 0 2 FWD.ReverseReads 0 0 0 0 3 REV.ForwardReads 0 0 0 0 4 REV.ReverseReads 0 0 0 0 "],["flujo-de-trabajo-de-dada2.html", "TEMA 4 : Flujo de trabajo de DADA2 4.1 Filtrado y corte de secuencias 4.2 Modelo de error 4.3 Dereplicación 4.4 Inferencia de ASVs 4.5 Uniendo secuencias 4.6 Remoción de quimeras 4.7 Estadísticos", " TEMA 4 : Flujo de trabajo de DADA2 Ubicar las secuencias ya limpias sin primers # Ruta cutFs &lt;- sort(list.files(path.cut, pattern = &quot;_1.fastq.gz&quot;, full.names = TRUE)) cutRs &lt;- sort(list.files(path.cut, pattern = &quot;_2.fastq.gz&quot;, full.names = TRUE)) # Extraer nombres get.sample.name &lt;- function(fname) strsplit(basename(fname), &quot;_&quot;)[[1]][1] sample.names &lt;- unname(sapply(cutFs, get.sample.name)) head(sample.names) [1] &quot;SRR24359981&quot; &quot;SRR24359982&quot; &quot;SRR24359983&quot; &quot;SRR24359984&quot; &quot;SRR24359985&quot; &quot;SRR24359986&quot; [1] &quot;SRR24359981&quot; &quot;SRR24359982&quot; &quot;SRR24359983&quot; &quot;SRR24359984&quot; &quot;SRR24359985&quot; &quot;SRR24359986&quot; Realizar un gráfico de inspección de calidad plotQualityProfile(cutFs[1:2]) plotQualityProfile(cutRs[1:2]) 4.1 Filtrado y corte de secuencias # duración: 10 min aprox filtFs &lt;- file.path(ruta_resultados, &quot;filtered2&quot;, basename(fnFs)) filtRs &lt;- file.path(ruta_resultados, &quot;filtered2&quot;, basename(fnRs)) filtFs names(filtFs) &lt;- sample.names names(filtRs) &lt;- sample.names out &lt;- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(280,200),maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,compress=TRUE, multithread=TRUE) out reads.in reads.out 1 SRR24359981_1.fastq.gz 5889 5421 2 SRR24359982_1.fastq.gz 13192 10710 3 SRR24359983_1.fastq.gz 67187 59786 4 SRR24359984_1.fastq.gz 2714 1987 5 SRR24359985_1.fastq.gz 6938 6311 6 SRR24359986_1.fastq.gz 11226 10113 7 SRR24359987_1.fastq.gz 10946 9889 8 SRR24359988_1.fastq.gz 4788 4333 9 SRR24359989_1.fastq.gz 14021 12780 10 SRR24359990_1.fastq.gz 9568 8747 11 SRR24359991_1.fastq.gz 14058 12885 12 SRR24359992_1.fastq.gz 19924 17665 13 SRR24359993_1.fastq.gz 15422 13550 14 SRR24359994_1.fastq.gz 13674 12257 15 SRR24359995_1.fastq.gz 13764 12503 16 SRR24359996_1.fastq.gz 12893 11605 17 SRR24359997_1.fastq.gz 14997 13854 18 SRR24359998_1.fastq.gz 20402 18873 19 SRR24359999_1.fastq.gz 8388 7575 20 SRR24360000_1.fastq.gz 233 137 21 SRR24360001_1.fastq.gz 7907 7258 22 SRR24360002_1.fastq.gz 18235 15919 23 SRR24360003_1.fastq.gz 15561 12958 24 SRR24360004_1.fastq.gz 9920 8982 25 SRR24360005_1.fastq.gz 7145 6534 26 SRR24360006_1.fastq.gz 4469 4127 27 SRR24360007_1.fastq.gz 20350 19168 28 SRR24360008_1.fastq.gz 6774 6181 29 SRR24360009_1.fastq.gz 12372 11009 30 SRR24360010_1.fastq.gz 8995 7282 31 SRR24360011_1.fastq.gz 10891 9841 32 SRR24360012_1.fastq.gz 5625 4369 33 SRR24360013_1.fastq.gz 16868 15110 34 SRR24360014_1.fastq.gz 9582 8602 35 SRR24360015_1.fastq.gz 3605 3339 36 SRR24360016_1.fastq.gz 16880 15814 37 SRR24360017_1.fastq.gz 10697 9997 38 SRR24360018_1.fastq.gz 6541 6037 39 SRR24360019_1.fastq.gz 7127 6428 40 SRR24360020_1.fastq.gz 50094 44708 41 SRR24360021_1.fastq.gz 11912 10810 42 SRR24360022_1.fastq.gz 15916 14526 43 SRR24360023_1.fastq.gz 36886 33962 44 SRR24360024_1.fastq.gz 12172 11240 45 SRR24360025_1.fastq.gz 664 567 46 SRR24360026_1.fastq.gz 10303 9100 47 SRR24360027_1.fastq.gz 8357 7340 48 SRR24360028_1.fastq.gz 7266 6521 49 SRR24360029_1.fastq.gz 6145 5590 50 SRR24360030_1.fastq.gz 11838 10869 51 SRR24360031_1.fastq.gz 8901 8150 52 SRR24360032_1.fastq.gz 6972 6379 53 SRR24360033_1.fastq.gz 92 49 54 SRR24360034_1.fastq.gz 13502 12328 55 SRR24360035_1.fastq.gz 64861 59232 56 SRR24360036_1.fastq.gz 16378 14781 57 SRR24360037_1.fastq.gz 15528 14129 58 SRR24360038_1.fastq.gz 17427 15852 59 SRR24360039_1.fastq.gz 4961 4537 60 SRR24360040_1.fastq.gz 6158 5629 61 SRR24360041_1.fastq.gz 14396 13291 62 SRR24360042_1.fastq.gz 12343 10919 63 SRR24360043_1.fastq.gz 22064 19992 64 SRR24360044_1.fastq.gz 14051 12977 65 SRR24360045_1.fastq.gz 11921 10472 4.2 Modelo de error #duración = 11 min aprox. errF &lt;- learnErrors(filtFs, multithread = TRUE) errR &lt;- learnErrors(filtRs, multithread = TRUE) png(&quot;error_model.png&quot;, units = &quot;in&quot;, height = 7, width = 10, res = 300) plotErrors(errF) dev.off() 4.3 Dereplicación #duración = 2 min aprox derepFs &lt;- derepFastq(filtFs, verbose = TRUE) derepRs &lt;- derepFastq(filtRs, verbose = TRUE) #saveRDS(derepFs, &quot;derepFs.RDS&quot;) 4.4 Inferencia de ASVs #duración = 4 min aprox dadaFs &lt;- dada(derepFs, err = errF, multithread = TRUE) dadaRs &lt;- dada(derepRs, err = errR, multithread = TRUE) #saveRDS(dadaRs, &quot;dadaRs.RDS&quot;) 4.5 Uniendo secuencias mergers &lt;- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE) #saveRDS(mergers, &quot;mergers.RDS&quot;) 4.6 Remoción de quimeras #tabla seqtab &lt;- makeSequenceTable(mergers) dim(seqtab) [1] 65 3079 #remoción quimeras seqtab_nochim &lt;- removeBimeraDenovo(seqtab, method = &quot;consensus&quot;, multithread = T, verbose = T) Identified 2017 bimeras out of 3079 input sequences. dim(seqtab_nochim) [1] 65 1062 4.7 Estadísticos getN &lt;- function(x)sum(getUniques(x)) stats &lt;- cbind( out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab_nochim) ) colnames(stats) &lt;- c(&quot;input&quot;, &quot;filtered&quot;, &quot;denoisedF&quot;, &quot;denoisedR&quot;, &quot;merged&quot;, &quot;nonchim&quot;) stats write.csv(stats, &quot;denoising-stats.csv&quot;) X input filtered denoisedF denoisedR merged nonchim NA. 1 SRR24359981 SRR24359981_1.fastq.gz 5889 5513 5489 5490 15 15 2 SRR24359982 SRR24359982_1.fastq.gz 13192 10957 10489 10354 107 105 3 SRR24359983 SRR24359983_1.fastq.gz 67187 61576 61466 61379 177 161 4 SRR24359984 SRR24359984_1.fastq.gz 2714 2123 1593 1573 154 154 5 SRR24359985 SRR24359985_1.fastq.gz 6938 6464 6421 6408 8 8 6 SRR24359986 SRR24359986_1.fastq.gz 11226 10334 10249 10235 0 0 7 SRR24359987 SRR24359987_1.fastq.gz 10946 10073 10029 10016 6 6 8 SRR24359988 SRR24359988_1.fastq.gz 4788 4425 4367 4392 45 45 9 SRR24359989 SRR24359989_1.fastq.gz 14021 12962 12919 12856 8 7 10 SRR24359990 SRR24359990_1.fastq.gz 9568 8852 8825 8745 0 0 11 SRR24359991 SRR24359991_1.fastq.gz 14058 13101 13071 13044 0 0 12 SRR24359992 SRR24359992_1.fastq.gz 19924 18150 18026 17991 16 16 13 SRR24359993 SRR24359993_1.fastq.gz 15422 13912 13714 13672 26 21 14 SRR24359994 SRR24359994_1.fastq.gz 13674 12501 12374 12281 37 35 15 SRR24359995 SRR24359995_1.fastq.gz 13764 12770 12737 12719 37 36 16 SRR24359996 SRR24359996_1.fastq.gz 12893 11809 11704 11698 0 0 17 SRR24359997 SRR24359997_1.fastq.gz 14997 14084 14024 13984 77 69 18 SRR24359998 SRR24359998_1.fastq.gz 20402 19153 19080 19061 57 52 19 SRR24359999 SRR24359999_1.fastq.gz 8388 7731 7690 7646 49 45 20 SRR24360000 SRR24360000_1.fastq.gz 233 155 38 26 0 0 21 SRR24360001 SRR24360001_1.fastq.gz 7907 7410 7383 7358 19 19 22 SRR24360002 SRR24360002_1.fastq.gz 18235 16334 16214 16122 84 82 23 SRR24360003 SRR24360003_1.fastq.gz 15561 13356 12628 12593 346 346 24 SRR24360004 SRR24360004_1.fastq.gz 9920 9218 9175 9173 27 27 25 SRR24360005 SRR24360005_1.fastq.gz 7145 6648 6625 6600 18 18 26 SRR24360006 SRR24360006_1.fastq.gz 4469 4195 4134 4126 11 11 27 SRR24360007 SRR24360007_1.fastq.gz 20350 19402 19362 19317 62 61 28 SRR24360008 SRR24360008_1.fastq.gz 6774 6276 6260 6233 0 0 29 SRR24360009 SRR24360009_1.fastq.gz 12372 11262 11087 11009 96 96 30 SRR24360010 SRR24360010_1.fastq.gz 8995 7589 7099 7057 155 155 31 SRR24360011 SRR24360011_1.fastq.gz 10891 10124 10090 9969 49 48 32 SRR24360012 SRR24360012_1.fastq.gz 5625 4475 4448 4437 4 4 33 SRR24360013 SRR24360013_1.fastq.gz 16868 15398 15339 15291 10 10 34 SRR24360014 SRR24360014_1.fastq.gz 9582 8820 8725 8715 38 37 35 SRR24360015 SRR24360015_1.fastq.gz 3605 3401 3321 3306 11 11 36 SRR24360016 SRR24360016_1.fastq.gz 16880 16037 15993 15990 10 10 37 SRR24360017 SRR24360017_1.fastq.gz 10697 10103 10046 10026 18 18 38 SRR24360018 SRR24360018_1.fastq.gz 6541 6139 6075 6078 20 20 39 SRR24360019 SRR24360019_1.fastq.gz 7127 6562 6493 6432 5 5 40 SRR24360020 SRR24360020_1.fastq.gz 50094 45966 45920 45755 77 72 41 SRR24360021 SRR24360021_1.fastq.gz 11912 11036 11007 10962 25 25 42 SRR24360022 SRR24360022_1.fastq.gz 15916 14774 14749 14730 12 12 43 SRR24360023 SRR24360023_1.fastq.gz 36886 34570 34448 34454 7 7 44 SRR24360024 SRR24360024_1.fastq.gz 12172 11371 11354 11241 7 7 45 SRR24360025 SRR24360025_1.fastq.gz 664 586 405 340 30 30 46 SRR24360026 SRR24360026_1.fastq.gz 10303 9374 9301 9301 15 15 47 SRR24360027 SRR24360027_1.fastq.gz 8357 7543 7411 7416 0 0 48 SRR24360028 SRR24360028_1.fastq.gz 7266 6714 6640 6627 71 71 49 SRR24360029 SRR24360029_1.fastq.gz 6145 5701 5662 5645 24 24 50 SRR24360030 SRR24360030_1.fastq.gz 11838 11076 11016 10990 29 29 51 SRR24360031 SRR24360031_1.fastq.gz 8901 8306 8274 8243 30 30 52 SRR24360032 SRR24360032_1.fastq.gz 6972 6487 6434 6441 37 37 53 SRR24360033 SRR24360033_1.fastq.gz 92 51 12 10 0 0 54 SRR24360034 SRR24360034_1.fastq.gz 13502 12609 12578 12550 35 34 55 SRR24360035 SRR24360035_1.fastq.gz 64861 60707 60394 60359 308 267 56 SRR24360036 SRR24360036_1.fastq.gz 16378 15110 15025 15047 57 56 57 SRR24360037 SRR24360037_1.fastq.gz 15528 14491 14412 14406 13 13 58 SRR24360038 SRR24360038_1.fastq.gz 17427 16273 16212 16160 32 32 59 SRR24360039 SRR24360039_1.fastq.gz 4961 4619 4578 4530 17 17 60 SRR24360040 SRR24360040_1.fastq.gz 6158 5699 5662 5639 0 0 61 SRR24360041 SRR24360041_1.fastq.gz 14396 13530 13243 13139 6 6 62 SRR24360042 SRR24360042_1.fastq.gz 12343 11171 10972 10992 106 106 63 SRR24360043 SRR24360043_1.fastq.gz 22064 20433 20363 20370 83 77 64 SRR24360044 SRR24360044_1.fastq.gz 14051 13211 13180 13083 37 37 65 SRR24360045 SRR24360045_1.fastq.gz 11921 10777 10567 10555 69 69 "],["asignación-taxonómica.html", "TEMA 5 : Asignación taxonómica 5.1 Base de datos Greengenes2 5.2 Asignación taxonómica", " TEMA 5 : Asignación taxonómica 5.1 Base de datos Greengenes2 En la siguiente parte se descarga la base de datos de greengenes2 y se depura manualmente en R. Esta parte no la vamos a correr, solo dejamos el script para que lo intentes con más tiempo y disponibilidad. #https://github.com/benjjneb/dada2/issues/1680#issuecomment-1724495374 download.file(&quot;http://ftp.microbio.me/greengenes_release/current/2024.09.backbone.full-length.fna.qza&quot;, &quot;2024.09.backbone.full-length.fna.qza&quot;) download.file(&quot;http://ftp.microbio.me/greengenes_release/current/2024.09.backbone.tax.qza&quot;, &quot;2024.09.backbone.tax.qza&quot;) unzip(&quot;2024.09.backbone.full-length.fna.qza&quot;) unzip(&quot;2024.09.backbone.tax.qza&quot;) fn &lt;- &quot;5b42d9b6-2f24-4f01-b989-9b4dafca7d5e/data/dna-sequences.fasta&quot; txfn &lt;- &quot;b7c3e691-ea51-4547-94dd-f79f49e41a36//data/taxonomy.tsv&quot; sq &lt;- getSequences(fn) tdf &lt;- read.csv(txfn, sep=&quot;\\t&quot;, header=TRUE) tdf2 &lt;- tdf[match(names(sq), tdf$Feature.ID),] tax &lt;- tdf2[,2] names(tax) &lt;- tdf2[,1] identical(names(sq), names(tax)) # TRUE taxes &lt;- strsplit(tax, &quot;; &quot;) tax.depth &lt;- sapply(taxes, length) table(tax.depth) # Todas las taxonomias son de 7 niveles # Nota: Las especies tienen generos con nombres duplicados en vez de especies # Remover el género de las especies for(i in seq(length(taxes))) { gen &lt;- taxes[[i]][[6]] gen &lt;- substr(gen, 4, nchar(gen)) taxes[[i]][[7]] &lt;- gsub(gen, &quot;&quot;, taxes[[i]][[7]]) taxes[[i]][[7]] &lt;- gsub(&quot;__ &quot;, &quot;__&quot;, taxes[[i]][[7]]) } tax_pre &lt;- c(&quot;d__&quot;, &quot;p__&quot;, &quot;c__&quot;, &quot;o__&quot;, &quot;f__&quot;, &quot;g__&quot;, &quot;s__&quot;) is.unassigned &lt;- sapply(taxes, function(tx) { tx == tax_pre }) |&gt; t() tax.depth &lt;- apply(is.unassigned, 1, function(isu) { min(which(isu)-1L, 7L) }) tax.ids &lt;- sapply(seq_along(taxes), function(i) { td &lt;- tax.depth[[i]] id.str &lt;- paste(taxes[[i]][1:td], collapse=&quot;;&quot;) id.str &lt;- paste0(id.str, &quot;;&quot;) # Add terminal semicolon id.str }) names(tax.ids) &lt;- names(taxes) # Write out the training fasta file sq.out &lt;- sq names(sq.out) &lt;- tax.ids writeFasta(sq.out, &quot;greengenes2_trainset.fa.gz&quot;, compress=TRUE) # Sanity test the results of `assignTaxonomy` on this newly created training dada2:::tax.check(&quot;greengenes2_trainset.fa.gz&quot;, fn.test=system.file(&quot;extdata&quot;, &quot;ten_16s.100.fa.gz&quot;, package=&quot;dada2&quot;)) Te dejamos mejor la liga para que descargues la base de datos de referencia ya depurada en su última versión, Liga La descargamos y la ponemos en nuestro directorio de trabajo. 5.2 Asignación taxonómica #duración : aprox 7 min classifier &lt;- &quot;greengenes2_trainset.fa.gz&quot; taxa &lt;- assignTaxonomy(seqtab_nochim, classifier, multithread = TRUE, tryRC = TRUE) # Visualizar lo que se genero despues de la asignacion taxa_print &lt;- taxa rownames(taxa_print) &lt;- NULL head(taxa_print) dim(taxa_print) Kingdom Phylum Class Order 1 1 d__Bacteria p__Pseudomonadota c__Gammaproteobacteria o__Burkholderiales 2 2 d__Bacteria p__Pseudomonadota c__Gammaproteobacteria o__Burkholderiales 3 3 d__Bacteria p__Pseudomonadota c__Gammaproteobacteria o__Burkholderiales 4 4 d__Bacteria p__Pseudomonadota c__Gammaproteobacteria o__Burkholderiales 5 5 d__Bacteria p__Pseudomonadota c__Gammaproteobacteria o__Burkholderiales 6 6 d__Bacteria &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; Family Genus Species 1 f__Burkholderiaceae_A_595421 &lt;NA&gt; &lt;NA&gt; 2 f__Burkholderiaceae_A_595421 &lt;NA&gt; &lt;NA&gt; 3 f__Burkholderiaceae_A_595421 &lt;NA&gt; &lt;NA&gt; 4 f__Burkholderiaceae_A_595421 &lt;NA&gt; &lt;NA&gt; 5 f__Burkholderiaceae_A_595421 &lt;NA&gt; &lt;NA&gt; 6 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; [1] 134 8 # Exportar objetos generados durante el preprocesamiento save( errF, dadaFs, dadaRs,seqtab_nochim, taxa, file = &quot;data.RData&quot;) write.csv(taxa, &quot;taxonomy.csv&quot;) write.csv(seqtab_nochim, &quot;table.csv&quot;) write.csv(stats, &quot;stats.csv&quot;) "],["análisis-exploratorio.html", "TEMA 6 : Análisis exploratorio 6.1 Composición taxonómica 6.2 Diversidad alfa 6.3 Diversidad beta", " TEMA 6 : Análisis exploratorio Primero vamos a cargar las librerías a usar library(phyloseq) library(Biostrings) library(tidyverse) theme_set(theme_bw()) Cargamos la metadata y ordenamos samples.out &lt;- rownames(seqtab_nochim) samdf &lt;-read.delim(&quot;Datos/seqs_transfer/sra-metadata.tsv&quot;) %&gt;% dplyr::rename(Origen=&quot;Host.Life.Stage..sample.&quot;, Tipo=&quot;Host.Tissue.Sampled..sample.&quot;) seqtab.nochim &lt;- seqtab_nochim[match(samdf$ID, rownames(seqtab_nochim)),] rownames(samdf) &lt;- samdf$ID Construimos un objeto phyloseq ps &lt;- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE), sample_data(samdf), tax_table(taxa)) ps phyloseq-class experiment-level object otu_table() OTU Table: [ 1062 taxa and 65 samples ] sample_data() Sample Data: [ 65 samples by 39 sample variables ] tax_table() Taxonomy Table: [ 1062 taxa by 7 taxonomic ranks ] Renombramos los ids de las secuencias y agregamos el rep_seqs dna &lt;- Biostrings::DNAStringSet(taxa_names(ps)) names(dna) &lt;- taxa_names(ps) ps &lt;- merge_phyloseq(ps, dna) taxa_names(ps) &lt;- paste0(&quot;ASV&quot;, seq(ntaxa(ps))) ps phyloseq-class experiment-level object otu_table() OTU Table: [ 1062 taxa and 65 samples ] sample_data() Sample Data: [ 65 samples by 39 sample variables ] tax_table() Taxonomy Table: [ 1062 taxa by 7 taxonomic ranks ] refseq() DNAStringSet: [ 1062 reference sequences ] 6.1 Composición taxonómica ps.prop &lt;- transform_sample_counts(ps, function(OTU) OTU/sum(OTU)) 6.1.1 Phylum my_phyla &lt;- tax_glom(ps.prop ,taxrank = &quot;Phylum&quot;) my_bar_phyla &lt;- plot_bar(my_phyla, fill=&quot;Phylum&quot;) + facet_grid(~Origen+Tipo, scales=&quot;free_x&quot;)+ ggtitle(&quot;Abundancia relativa de Filos&quot;) my_bar_phyla 6.1.2 Class my_Class &lt;- tax_glom(ps.prop ,taxrank = &quot;Class&quot;) my_bar_Class &lt;- plot_bar(my_Class, fill=&quot;Class&quot;) + facet_grid(~Origen+Tipo, scales=&quot;free_x&quot;)+ ggtitle(&quot;Abundancia relativa de clases&quot;) my_bar_Class 6.2 Diversidad alfa Primero hacemos subconjuntos del origen #madre madre &lt;- subset_samples(ps, Origen==&quot;adult&quot;) madre phyloseq-class experiment-level object otu_table() OTU Table: [ 1062 taxa and 29 samples ] sample_data() Sample Data: [ 29 samples by 39 sample variables ] tax_table() Taxonomy Table: [ 1062 taxa by 7 taxonomic ranks ] refseq() DNAStringSet: [ 1062 reference sequences ] #embrion embrion &lt;- subset_samples(ps, Origen==&quot;embryo&quot;) embrion phyloseq-class experiment-level object otu_table() OTU Table: [ 1062 taxa and 36 samples ] sample_data() Sample Data: [ 36 samples by 39 sample variables ] tax_table() Taxonomy Table: [ 1062 taxa by 7 taxonomic ranks ] refseq() DNAStringSet: [ 1062 reference sequences ] Graficamos la diversidad alfa plot_richness(madre, x=&quot;Tipo&quot;, measures=c(&quot;Observed&quot;,&quot;Shannon&quot;, &quot;Simpson&quot;), color=&quot;Tipo&quot;) plot_richness(madre, x=&quot;Tipo&quot;, measures=c(&quot;Observed&quot;,&quot;Shannon&quot;, &quot;Simpson&quot;), color=&quot;Tipo&quot;)+ geom_boxplot() plot_richness(embrion, x=&quot;Tipo&quot;, measures=c(&quot;Observed&quot;,&quot;Shannon&quot;, &quot;Simpson&quot;), color=&quot;Tipo&quot;)+ geom_boxplot() - rarificar si es necesario #ps_rare &lt;- rarefy_even_depth(ps_fil, sample.size = min(sample_sums(ps_fil)), rngseed = 19) #ps_rare 6.3 Diversidad beta # Transformar la data proporciones ps.prop &lt;- transform_sample_counts(ps, function(otu) otu/sum(otu)) ord.nmds.bray &lt;- ordinate(ps.prop, method=&quot;NMDS&quot;, distance=&quot;bray&quot;) Run 0 stress 0.1095504 Run 1 stress 0.09868059 ... New best solution ... Procrustes: rmse 0.09563604 max resid 0.5094939 Run 2 stress 0.1231022 Run 3 stress 0.1098466 Run 4 stress 0.1080524 Run 5 stress 0.1044585 Run 6 stress 0.0865813 ... New best solution ... Procrustes: rmse 0.05945264 max resid 0.4086972 Run 7 stress 0.1165887 Run 8 stress 0.1029955 Run 9 stress 0.1003513 Run 10 stress 0.1057944 Run 11 stress 0.09968048 Run 12 stress 0.1263871 Run 13 stress 0.1029865 Run 14 stress 0.1232351 Run 15 stress 0.08660667 ... Procrustes: rmse 0.01695323 max resid 0.08622676 Run 16 stress 0.09836792 Run 17 stress 0.08398756 ... New best solution ... Procrustes: rmse 0.01210169 max resid 0.08500781 Run 18 stress 0.1132728 Run 19 stress 0.1091269 Run 20 stress 0.1090214 *** Best solution was not repeated -- monoMDS stopping criteria: 2: no. of iterations &gt;= maxit 18: stress ratio &gt; sratmax plot_ordination(ps.prop, ord.nmds.bray, color=&quot;Tipo&quot;, shape=&quot;Origen&quot;,title=&quot;Bray NMDS&quot;) ord.nmds.jac &lt;- ordinate(ps.prop, method=&quot;PCoA&quot;, distance=&quot;jaccard&quot;) plot_ordination(ps, ord.nmds.jac, color=&quot;Tipo&quot;, shape=&quot;Origen&quot;,title=&quot;Bray NMDS&quot;) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
